---
title: "ST-558 Project 1"
author: ""
date: today
date-format: D MMMM YYYY
format: html
---

Get the usual process to work with a given URL.

```{r, }
library("tidyverse")
library("httr")
library("rjson")
```

```{r}
variables <- c("PWGTP","AGEP","SEX", "FER", "JWTRNS")
geography <- "state:01"
year <- "2022"
url <- paste0("https://api.census.gov/data/", year, "/acs/acs1/pums?")
res <- GET(url, query = list(get=paste(variables, collapse=","), `for`=geography))
```

Write a helper function to take what is returned by GET() and turn it into a nice tibble.

```{r}
get_pums_tibble <- function(html_page) {
    content <- content(html_page, as="parsed") #Parses the HTML content.
    content <- lapply(content, unlist) |> #Unlists each element in the parsed content. This creates a list of vectors.
                as.data.frame(col.names=1:length(content)) |> #Converts the list to a data frame, with column names as numbers.
                as.matrix() |> t() |> as_tibble() #Converts the data frame to a matrix, transposes it, and then converts it to a tibble.
    content <- content |> setNames(content[1,]) |> slice(-1) #Sets the first row as column names.   Then removes the first row (now used as column names)
    return(content) #returns a tibble.
}
```

**Data Processing Requirements**

Write a function to query the API that allows the user to change the following items:

R1.1 - Year of survey (2022 as default). Check that a valid value was given (number between 2010 and 2022)

R1.2 – Specify the numeric variables to be returned (AGEP and PWGTP as default). PWGTP should always be returned. Options for the user should be AGEP, GASP, GRPIP, JWAP (time), JWDP (time), and JWMNP

R1.2.1 - Your function should turn variables into numeric values or time values (use the middle of the time period) where appropriate. At least one numeric variable other than PWGTP must be returned

R1.3 - Specify the categorical variables to be returned (SEX as default).Options for the user should be FER, HHL, HISPEED, JWTRNS, SCH, SCHL, and SEX.

R1.3.1 - Your function should turn variables into factors with appropriate levels, where appropriate. At least one categorical variable must be returned. Check that the variables asked for are in this set of variables.

R1.4 – Specify the geography level: All, Region, Division, or State (with the default of All). Check that the value specified by the user is one of the above values

R1.4.1 – An optional argument to subset the data (this subsetting should be on the API call itself, not on what is returned - see the examples in the links above). The user should be able to specify specific Regions, Divisions, or States for this part (and only those specified geography levels would be returned) ∗ How you allow them to specify this is up to you (you’ll have to parse it appropriately). The requirement is one state or all states (same for other geography hierarchy).

```{r Single Year Function}
get_single_year <- function(year = 2022, num_vars = c("AGEP", "PWGTP"), 
                            cat_vars = c("SEX"), geography = "State", geography_level = c(":13")) {
    # R1.1- Validate Survey Year
    if (!is.numeric(year)) {
        stop("Year must be numeric")
    } 
    if (!(year >= 2010 & year <= 2022)) {
        stop("Year must be between 2010 and 2022 inclusive")
    }
    # R1.2 - Validate Numeric Variables
    if (!("PWGTP" %in% num_vars)) {
        stop("PWGTP must be included in the numeric variables")
    }
    if (length(num_vars) < 2) {
        stop("At least one numeric variable besides PWGTP is required")
    }
    if (!all(num_vars %in% 
             c("AGEP","GASP","GRPIP","JWAP","JWDP","JWMNP","PWGTP"))) {
        stop("Undefined numeric variable(s)")
    }
    # R1.3 Validate Categorical Variables
    if (length(cat_vars) == 0) {
        stop("At least one categorical variable required")
    }
    if (!all(cat_vars %in% c("FER", "HHL", "HISPEED", "JWTRNS", "SCH", "SCHL", 
                             "SEX"))) {
        stop("Undefined categorical variable(s)")
    }
    # Validate Region Variable
    
    if (!(geography %in% c("State", "Division", "Region"))) {
        stop("Geography must be 'Region', 'Division' or 'State'")
    }
   
     #R1.4 - Validate Geography Level
    #State Check
    if (geography == "State" && (as.numeric(geography_level) %in% 0:50) == FALSE)
       {stop("Valid State values are between 01 and 50")

    #Division Check
    } else if (geography == "Division" && (as.numeric(geography_level) %in% 1:9) == FALSE)
    {stop("Valid Division values are between 0 and 9")

    #Region Check
    } else if (geography == "Region" && (as.numeric(geography_level) %in% c(1,2,3,4) == FALSE))
    {stop("Valid Region values are 1,2,3,4")

    } 

    
    #Create geography argument for the query
    geography <- paste0(geography, ":", paste(geography_level, collapse = ","))
     
     
    url <- paste0("https://api.census.gov/data/", as.character(year), 
                  "/acs/acs1/pums?")
    res <- GET(url, query = list(get=paste(c(num_vars, cat_vars), 
                                collapse=","), `for`=geography))
    
    #Check if variables are present in selected year
    
    
    
    
    df <- get_pums_tibble(res)

    #R1.2.1 - Convert Journey to Work Departure Time to HH:MM Format
    if ("JWDP" %in% num_vars && "JWDP" %in% names(df)) {
    df <- df |> mutate(JWDP = str_pad(JWDP, width = 3, side = "left", pad = "0"))

        jwdp_file <- paste0("https://api.census.gov/data/", as.character(year),
                                "/acs/acs1/pums/variables/JWDP.json")
        #Creates the URL to download the JWDP code mapping for the specified year.
        
        jwdp_map <- fromJSON(paste(readLines(jwdp_file), collapse=""))$values$item |> as.list()
        #Downloads and reads the JSON file, extracts the mapping of JWDP codes to time ranges, and converts it to a list.

        names(jwdp_map)[names(jwdp_map) == "0"] <- "000"
        #Renames the mapping key "0" to "000" to match the padded JWDP codes. This line subsets the names of the keys that are 0 and then converting them to "000"

        for (i in 1:nrow(df)) {
            #Starts a loop over each row in the data frame.
            if (df$JWDP[i] == "000") {
                df$JWDP[i] <- NA
            #If the JWDP code is "000" (which means "Not applicable"), sets it to NA.
            } else {
                iv <- strsplit(jwdp_map[[ df$JWDP[i] ]], " to ")[[1]] |> str_remove_all("\\.") |> 
                    str_to_upper()
                #Otherwise, splits the mapped time range (e.g., "5:00 a.m. to 5:29 a.m.") into start and end times,
                #removes periods, and converts to uppercase.
                
                mid <- ((as.numeric(parse_time(iv[2])) + as.numeric(parse_time(iv[1])) ) / 2)
                #Parses the start and end times, converts them to numeric (seconds or minutes), and calculates the midpoint.
                df$JWDP[i] <- mid
                #Assigns the midpoint value back to the JWDP column for that row.
            }
        }
        df <- df |> mutate(JWDP = hms::as_hms(as.numeric(JWDP)))
        #Converts the JWDP column to HMS (hour-minute-second) time format.
        #Converts the JWDP column to numeric values (if it isn’t already).
  
        
        num_vars <- num_vars[num_vars != "JWDP"]
        # Removes "JWDP" from the num_vars vector, since it is no longer a numeric variable.
    }
    
    #R1.2.1 - Convert Journey to Work Arrival Time to HH:MM Format
    if ("JWAP" %in% num_vars && "JWAP" %in% names(df)) {
    df <- df |> mutate(JWAP = str_pad(JWAP, width = 3, side = "left", pad = "0"))

        jwap_file <- paste0("https://api.census.gov/data/", as.character(year),
                            "/acs/acs1/pums/variables/JWAP.json")
        jwap_map <- fromJSON(paste(readLines(jwap_file), collapse=""))$values$item |> as.list()

        names(jwap_map)[names(jwap_map) == "0"] <- "000"

        for (i in 1:nrow(df)) {
            if (df$JWAP[i] == "000") {
                df$JWAP[i] <- NA
            } else {
                iv <- strsplit(jwap_map[[ df$JWAP[i] ]], " to ")[[1]] |> str_remove_all("\\.") |> 
                    str_to_upper()
                mid <- ((as.numeric(parse_time(iv[2])) + as.numeric(parse_time(iv[1])) ) / 2)
                df$JWAP[i] <- mid
            }
        }
        df <- df |> mutate(JWAP = hms::as_hms(as.numeric(JWAP)))
        num_vars <- num_vars[num_vars != "JWAP"]
    }
    
    #R1.3.1 - Convert Categorical Variables into Factors with Levels
#    cat_var_maps <- list()
    for (variable in cat_vars) {
        #Iterates through each variable name in the vector cat_vars.
        var_url <- paste0("https://api.census.gov/data/", year, "/acs/acs1/pums/variables/", variable, ".json")
        #Constructs the URL to download the JSON codebook for the current variable and year.
        var_map <- fromJSON(paste(readLines(var_url), collapse=""))$values$item
        #Downloads the JSON file, reads it as a single string, parses it, and extracts the mapping of codes to labels for the variable.
        names(var_map) <- str_replace(names(var_map), "^0+(?!$)", "")
        #Removes leading zeros from the code names (except for the value "0"), so that codes in the data (which may not have leading zeros) will match the codebook. 
        
        df[[variable]] <- factor(df[[variable]], levels = names(var_map), labels = unlist(unname(var_map)))
        #Converts the column df[[variable]] (for each cat_var) into a factor:in the data frame to a factor, using the cleaned code names as levels and the corresponding labels from the codebook as the factor labels.
    }
 
    #R1.2.1 - Convert Numeric Variables to Numeric
    df <- df |> mutate(across(all_of(num_vars), ~ as.numeric(.)))
    
    return(df)
}


```

R1.5 - write a function that allows the user to specify multiple years of survey data (and all the other options above). This function should call your single year function as many times as needed and then combine the data into one final tibble (a year variable should be included in this final tibble).

```{r Multi Year Function R1.5}
get_multi_years <- function(years = c(2022), num_vars = c("AGEP", "PWGTP"),
                            cat_vars = c("SEX"), geography = "State", geography_level = c("13")) {
  myear_tibble <- lapply(years, function(y) 
    get_single_year(y, num_vars, cat_vars, geography, geography_level)
  ) |> 
    map2_dfr(years, ~ mutate(.x, year = .y))
  return(myear_tibble)
}
 my_tibble <- myear_tibble
    
     #lapply(years, function (y) get_single_year(...)): For each year in years, calls the function get_single_year() with the specified parameters, returning a list of tibbles (one per year). The result is a list: each element is a tibble for a specific year. The pipe |> passes this list to map2_dfr(years, ~ mutate(.x, year = .y)):
    
    #map2_dfr() iterates over the list of tibbles and the years vector in parallel.
    #mutate(.x, year = .y) is used inside map2_dfr() to add a new column called year to each tibble .x, setting its value to .y (the corresponding year). .x is the current tibble (data for one year). .y is the current year from the years vector.y. #map2_dfr() then binds all the tibbles together row-wise into a single tibble.




```

**Obtaining Person Level Records**

Lastly, we need to process the data in our tibble appropriately. The PWGTP variable actually represents the number of (people) observations there should be for a particular row. PWGTP is the number of people in a household. If we wanted to look at individuals, we would have to create new rows to represent the individuals.

We won’t do this, but we could create a new tibble with each row replicated PWGTP times. (This would create very large data frames in some instances and processing would be slow!)

**Writing a Generic Function for Summarizing**

R2.1 Create your own custom object class called census.

R2.2 Create your own summary function that produces summary statistics on the census object.

R2.2.1 For the census summary method, let’s write a function that produces means and standard deviations for our numeric variable(s) and counts for our categorical variable(s).

R2.2.2 - This function should take three arguments: the tibble with class census, the numeric variable(s) to summarize, the categorical variable(s) to summarize.

R2.2.3 - By default, it should summarize all numeric variables (other than PWGTP) and all categorical variables in the tibble. However, the user should be able to specify the variables they’d like to summarize if they’d like.

If num_vars = cat_vars = NULL, return a list of tibbles from my_tibble. If not, then return a list of tibbles based on the arguments in num_vars and cat_vars. PWGTP is a frequency count. See project prompt. Return the means and standard deviations as a named list.

```{r Summary Function R2.2}
summary.census <- function(tibble, num_vars = NULL, cat_vars = NULL) {
    #check if num_vars is TRUE
    mean_tibble <- sd_tibble <- freq_tibble <- NULL
    
    if (!is.null(num_vars)) {
        mean_tibble <- tibble |> summarise(across(all_of(num_vars) & !all_of("PWGTP"),
                                         ~ sum(.x * PWGTP) / sum(PWGTP), .names = "{.col}_mean"))
        
        sd_tibble <- tibble |> summarise(across(all_of(num_vars) & !all_of("PWGTP"),
                        ~ sqrt(sum(.x^2 * PWGTP) / sum(PWGTP) - (sum(.x * PWGTP) / sum(PWGTP))^2 ), .names = "{.col}_sd"))
    }
        
    #check if cat_vars is TRUE
    if(!is.null(cat_vars)) {
    #summarize frequency counts    
        freq_tibble <- tibble |> group_by(across(all_of(cat_vars))) |> summarize(Freq=n())       

    }
    
    #default - return list of tibbles from my_tibble
    if (is.null(num_vars) && is.null(cat_vars)) {
        #compute means of all numeric variables (except PWGTP)
        mean_tibble <- tibble |> summarise(across(where(is.numeric) & !all_of("PWGTP"),
                                             ~ sum(.x * PWGTP) / sum(PWGTP), .names = "{.col}"))
            
        #compute standard deviation of all numeric variables (except PWGTP)
        sd_tibble <- tibble |> summarise(across(where(is.numeric) & !all_of("PWGTP"),
                            ~ sqrt( sum(.x^2 * PWGTP) / sum(PWGTP) - (sum(.x * PWGTP) / sum(PWGTP))^2 ), .names = "{.col}")) 
        
        #summarize frequency counts    
        freq_tibble <- tibble |> select(where(is.factor)) |> count(across(everything()), name = "Freq")
    }
    return(c(
        bind_rows(mean_tibble, sd_tibble) |>
        #Stacks the mean and standard deviation tibbles row-wise.
            mutate(stat = c("Mean", "Standard Deviation")) |>
            #Adds a stat column labeling each row.
            select(stat, everything()),
            #Moves the stat column to the front.
        freq_tibble)
        #c(..., freq_tibble): Combines the summary tibble and the frequency tibble into a list.
        )
}

# summary.census needs to be a method that summarizes a census object.

```

R2.2.4 Test out this function by running summary(*your_census_tibble*) on something you’ve returned from your census API function.

```{r Summary Function Verification}
syear_test <- get_single_year(num_vars = c("PWGTP","AGEP", "JWDP"),
                       cat_vars = c("SEX", "JWTRNS"),
                       geography = "Region", geography_level = c("2"))

class(syear_test) <- c("census", class(syear_test))

myear_test <- get_multi_years(years = c(2019, 2022), num_vars = c("PWGTP","AGEP", "JWDP"),
                       cat_vars = c("SEX", "JWTRNS"),
                       geography = "State", geography_level = c("02"))
    
class(myear_test) <- c("census", class(myear_test))

summary(syear_test)
summary(myear_test)

plot(syear_test)
plot(myear_test)

```

R2.3 - Similarly, let’s create a generic plot() function for a census class tibble. Require the user to specify one categorical variable and one numeric variable for plotting purposes.

```{r Plotting Function}

plot.census <- function()
{
library(ggplot2) # put this in your setup code chunk
ggplot(my_tibble,
aes(x = get(cat_vars), y = get(num_vars), weight = PWGTP)) +
 geom_boxplot()
}


# census.plot needs to be a method that summarizes a census object.
```

**Web Page**

R 3.1 - Your web page should have a narrative going through your process of creating the above functions and testing them.

R3.2 - You should have a section at the end where you investigate something interesting from the data using your API function and plotting/summarizing functions.
