---
title: "ST-558 Project 1"
author: ""
date: today
date-format: D MMMM YYYY
format: html
---
# Preprocessing
```{r}
library(tidyverse)
library(httr)
library(rjson)
library(ggplot2)
```

# Get the usual process to work with a given URL.
This code is simply a proof of concept query of the PUMS Census API. Variables are set for the
necessary API inputs which are then used to construct an URL to query `cenus.gov`. The `httr::GET()`
function contains `query` and `for` arguments which receptively take in PUMS API variables and geographic
region as inputs to finalize the URL and return an http response object. This object can be further
be parsed to extract the raw character data from the query.
```{r}
variables <- c("PWGTP","AGEP","SEX", "FER", "JWTRNS")
geography <- "state:01"
year <- "2022"
url <- paste0("https://api.census.gov/data/", year, "/acs/acs1/pums?")
res <- GET(url, query = list(get=paste(variables, collapse=","), `for`=geography))
```

# Write a helper function to take what is returned by GET() and turn it into a nice tibble.
The function `get_pums_tibble` takes in an http response object returned from `httr::GET()`, extracts
the raw character data using `httr::content`, and parses it into a formatted tibble, which is finally
returned. 
The process is given below:
1. Parses the HTML content with `httr::content`.
2. Each row of raw html text is returned as a list within a list. Each element must be unlisted into
    a list of vectors.
3. The list is converted into a data frame for easier manipulation. However, each row of raw html text
    becomes a column instead of a row in the data frame. The column names being text row numbers serve
    no purpose other than more readable output for debugging.
4. The data frame is converted into a matrix for an easier transpose operation. Transposing the matrix
    takes each observation represented as a column and transforms it into a row. Once the matrix is
    transformed into a standard format, it's converted into a tibble.
5. The variable names are stored in the first row. The first row is set as the column names and then dropped.
6. The formatted tibble is returned.

```{r}
get_pums_tibble <- function(html_page) {
    content <- content(html_page, as="parsed") #
    content <- lapply(content, unlist) |> 
                as.data.frame(col.names=1:length(content)) |> 
                as.matrix() |> t() |> as_tibble()
    content <- content |> setNames(content[1,]) |> slice(-1)
    return(content)
}
```

# Data Processing

This code block pulls a list of state codes from `census.gov` needed to check whether the user
specified state code is correct. On `census.gov` the variable key appears to only exist for 2021 or
later, but the same codes seem to work.
```{r}
# Needed for checking valid state codes
st_codes <- fromJSON(paste(readLines("https://api.census.gov/data/2022/acs/acs1/pums/variables/ST.json"),
                           collapse=""))$values$item |> names()
```

The function `get_single_year()` is for parsing a single year of census data from `census.gov` using
the PUMS API according to user specified numerical and categorical variables, the year, and a
geographical subset of the data by region, division, or state. The `get_single_year()` function
itself is too long and ideally would be split into 3 additonal functions. One for validating and
formatting user input. A second for calculating the midpoint of the time ranges in `JWDP` and `JWAP`
before converting them into an R time format. Finally, a third function for converting all the
categorical variables into factors with appropriate labels pulled from `census.gov`'s variable
descriptions. However, the project didn't require this, so the code will be left in a monolithic
format.

The first 50 lines of code in `get_single_year()` are for validating user input for `year`, numeric
variables, categorical variables, geography subset, and geography level. If any of these inputs are
not the correct data type, undefined options according to the project requirements, or disallowed
combinations of variables, then an appropriate error will be thrown. Many values for the correct
function arguments are hard coded included geography levels except the state codes. Finally since
variables change from year to year, all user supplied variables will be checked if they exist for
that given year. If all variables exist the query will proceed, otherwise a warning lets the user
know which variables aren't present during that year and an empty tibble is returned.

Once user input is validated, a URL string must be formatted to query the PUMS API. First, a string
represented the geography subset is formatted, which is then concatenated with the other components
of the URL. Then, the `httr:GET` function queries `cenus.gov` using the `query` and `for` arguments
to finalized the URL string and return an http response object. Next, `get_pums_tibble()` processes
the http object and returns a tibble with the parsed census data stored within. 

The bulk of the code in `get_single_year` contains logic for finding the midpoint of `JWDP` and `JWAP`
and converting it into HH:MM:SS format with the `hms` package. However, these variables are factors
corresponding to time ranges represented as strings in a non-standard format. So, first the variable
descriptions must be pulled from `census.gov` and converted into a map to decode the raw data. However,
this revealed another issue where the key in the key-value pairs mapping the factor to its description
all have a length of 3. So, the raw data needs to be padded to match the variable description keys.
The resulting process to decode the data follows these steps:

1. Pad raw data with zeros on the left to a maximum length of 3.
2. Construct the URL to download the JWDP code mapping for the specified year.
3. Downloads and reads the JSON file, extracts the mapping of JWDP codes to time ranges, and convert to a list.
4. Renames the mapping key "0" to "000" to match the padded JWDP raw data.
5. Loop over each row/observation in the tibble
    * If the JWDP code is "000" (which means "Not applicable"), sets it to NA.
    * Otherwise, splits the mapped time range (e.g., "5:00 a.m. to 5:29 a.m.") into start and end times,
    removes periods, and converts all characters to uppercase.
    * Parses the start and end times, converts them to numeric (seconds or minutes), and calculates the midpoint.
    * Assigns the midpoint value back to the JWDP column for that row.
    * Converts the JWDP column to numeric values (the tibble coerces it back to a character).
    * Converts the JWDP column to HMS (hour-minute-second) time format.
    * Removes "JWDP" from the num_vars vector, since it is no longer a numeric variable.

This approach is likely more complicated than it needs to be, but it was the first solution we developed.
One major issue with this approach is the for loop which is inherently slower in an interpreted language
like R, especially when multiple complex statements are nested within. In production, this code
should be rewritten for optimization. The same process is followed for both `JWDP` and `JWAP`.

The final portion of `get_single_year()` converts all categorical variables into factors with labels
pulled from the official variable descriptions queried from `census.gov`. The process of converting
the categorical variables into factors with levels is as follows:

1. Iterates through each variable in the vector cat_vars.
2. Constructs the URL to download the JSON variable map for the current variable and year.
3. Downloads the JSON file, reads it as a single string, parse it, and extracts the mapping of codes
    to labels for the variable.
4. Removes leading zeros from the code names (except for the value "0"), so that codes in the data
    (which may not have leading zeros) will match the JSON map keys. 
5. Converts the column df[[variable]] (for each cat_var) into a factor, using the cleaned names as
    levels and the corresponding labels from the map as the factor labels.
    
Last, the remaining numeric variables are converted from character to numeric and the tibble is returned.
Also, note there is no data for 2022.

```{r Single Year Function}
get_single_year <- function(year = 2022, num_vars = c("AGEP", "PWGTP"), 
                            cat_vars = c("SEX"), geography = "State", geography_level = c(":13")) {
    # Validate Survey Year
    if (!is.numeric(year)) {
        stop("Year must be numeric")
    } 
    if (!(year %in% c(2010:2019, 2021:2022))) {
        stop("Year must be between 2010 and 2019 or 2021, 2022")
    }
    # Validate Numeric Variables
    if (!("PWGTP" %in% num_vars)) {
        stop("PWGTP must be included in the numeric variables")
    }
    if (length(num_vars) < 2) {
        stop("At least one numeric variable besides PWGTP is required")
    }
    if (!all(num_vars %in% 
             c("AGEP","GASP","GRPIP","JWAP","JWDP","JWMNP","PWGTP"))) {
        stop("Undefined numeric variable(s)")
    }
    # Validate Categorical Variables
    if (length(cat_vars) == 0) {
        stop("At least one categorical variable required")
    }
    if (!all(cat_vars %in% c("FER", "HHL", "HISPEED", "JWTRNS", "SCH", "SCHL", "SEX"))) {
        stop("Undefined categorical variable(s)")
    }
    # Validate Region Variable
    if (!(geography %in% c("State", "Division", "Region"))) {
        stop("Geography must be 'Region', 'Division' or 'State'")
    }
    # Validate Geography Level
    if (geography == "State" && (geography_level %in% st_codes) == FALSE) {
        stop("Invalid State value. Find defined state codes at
             https://api.census.gov/data/2022/acs/acs1/pums/variables/ST.json")
    } 
    else if (geography == "Division" && (as.numeric(geography_level) %in% 1:9) == FALSE) {
        stop("Valid Division values are between 1 and 9")
    }
    else if (geography == "Region" && (as.numeric(geography_level) %in% 1:4 == FALSE)) {
        stop("Valid Region values are between 1 and 4")
    }
    
    #Check if variables are present in selected year
    all_vars <- paste0("https://api.census.gov/data/", as.character(year), "/acs/acs1/pums/variables") |>
        GET() |> content(as="parsed") |> tail(-1) |> lapply(`[[`, 1) |> unlist()
    
    if (!all(c(num_vars, cat_vars) %in% all_vars)) {
        warning(paste("The following variables: (",
                      setdiff(c(num_vars, cat_vars), all_vars),
                      ") are undefined for year",
                      as.character(year), sep = " "))
        return(tibble())
    }

    #Create geography argument for the query
    geography <- paste0(geography, ":", paste(geography_level, collapse = ","))
     
    url <- paste0("https://api.census.gov/data/", as.character(year), "/acs/acs1/pums?")
    res <- GET(url, query = list(get=paste(c(num_vars, cat_vars), collapse=","), `for`=geography))
    
    
    df <- get_pums_tibble(res)

    # Convert Journey to Work Departure Time to HH:MM Format
    if ("JWDP" %in% num_vars && "JWDP" %in% names(df)) {
        
        df <- df |> mutate(JWDP = str_pad(JWDP, width = 3, side = "left", pad = "0"))
        jwdp_file <- paste0("https://api.census.gov/data/", as.character(year),
                                "/acs/acs1/pums/variables/JWDP.json")
        jwdp_map <- fromJSON(paste(readLines(jwdp_file), collapse=""))$values$item |> as.list()

        names(jwdp_map)[names(jwdp_map) == "0"] <- "000"

        for (i in 1:nrow(df)) {
            if (df$JWDP[i] == "000") {
                df$JWDP[i] <- NA
            } else {
                iv <- strsplit(jwdp_map[[ df$JWDP[i] ]], " to ")[[1]] |> str_remove_all("\\.") |> 
                    str_to_upper()
                mid <- ((as.numeric(parse_time(iv[2])) + as.numeric(parse_time(iv[1])) ) / 2)
                df$JWDP[i] <- mid
            }
        }
        df <- df |> mutate(JWDP = hms::as_hms(as.numeric(JWDP)))
        num_vars <- num_vars[num_vars != "JWDP"]
    }
    
    # Convert Journey to Work Arrival Time to HH:MM Format
    if ("JWAP" %in% num_vars && "JWAP" %in% names(df)) {
    df <- df |> mutate(JWAP = str_pad(JWAP, width = 3, side = "left", pad = "0"))

        jwap_file <- paste0("https://api.census.gov/data/", as.character(year),
                            "/acs/acs1/pums/variables/JWAP.json")
        jwap_map <- fromJSON(paste(readLines(jwap_file), collapse=""))$values$item |> as.list()

        names(jwap_map)[names(jwap_map) == "0"] <- "000"

        for (i in 1:nrow(df)) {
            if (df$JWAP[i] == "000") {
                df$JWAP[i] <- NA
            } else {
                iv <- strsplit(jwap_map[[ df$JWAP[i] ]], " to ")[[1]] |> str_remove_all("\\.") |> 
                    str_to_upper()
                mid <- ((as.numeric(parse_time(iv[2])) + as.numeric(parse_time(iv[1])) ) / 2)
                df$JWAP[i] <- mid
            }
        }
        df <- df |> mutate(JWAP = hms::as_hms(as.numeric(JWAP)))
        num_vars <- num_vars[num_vars != "JWAP"]
    }
    
    # Convert Categorical Variables into Factors with Levels
    for (variable in cat_vars) {
        var_url <- paste0("https://api.census.gov/data/", year, "/acs/acs1/pums/variables/", variable, ".json")
        var_map <- fromJSON(paste(readLines(var_url), collapse=""))$values$item
        names(var_map) <- str_replace(names(var_map), "^0+(?!$)", "")
        df[[variable]] <- factor(df[[variable]], levels = names(var_map), labels = unlist(unname(var_map)))
    }
    # Convert Numeric Variables to Numeric
    df <- df |> mutate(across(all_of(num_vars), ~ as.numeric(.)))
    
    return(df)
}
```

# Write a function that allows the user to specify multiple years of survey data
The `get_multi_years()` function takes in the same arguments as `get_single_year` with one exception,
year is a vector of numbers rather than a single number. First `lapplay()` iterates over the
years vector calling `get_single_year()` for each element which returns a list of tibbles, one
for each year. `mutate(.x, year = .y) ` is used inside `map2_dfr()` to add a new column called year
to each tibble `.x,` setting its value to `.y` (the corresponding year).`.x` is the current tibble
(data for one year). `.y` is the current year from the years vector.`map2_dfr()` then binds all
the tibbles together row-wise into a single tibble.

```{r Multi Year Function R1.5}
get_multi_years <- function(years = c(2022), num_vars = c("AGEP", "PWGTP"),
                            cat_vars = c("SEX"), geography = "State", geography_level = c("13")) {
    myear_tibble <- lapply(years, function(y) 
        get_single_year(y, num_vars, cat_vars, geography, geography_level)) |> 
        map2_dfr(years, ~ mutate(.x, year = .y))
    return(myear_tibble)
}
```

# Generic Function for Summarizing
R2.2.2 - This function should take three arguments: the tibble with class census, the numeric variable(s) to summarize, the categorical variable(s) to summarize.

R2.2.3 - By default, it should summarize all numeric variables (other than PWGTP) and all categorical variables in the tibble. However, the user should be able to specify the variables they’d like to summarize if they’d like.

This method belongs to the `census` class which is an object of type `tibble()` returned from a call
the either `get_single_year()` or `get_multi_year()`. This method will specify the behavior of the
generic function `summary()` uniquely for a `census` object. The function arguments take in a
census tibble and optionally vectors of numeric and categorical variables. By default, the weighted means
and standard deviations of all numeric variables and the weighted counts of all categorical variables
will be returned. However, if the user specifies a vector of numeric or categorical variables in the
function call, only summaries of those variables will be returned. `PWGTP` being a frequency count per household
will not be summarized and will act as the weight for the means, standard deviations, and overall counts
for each level of the categorical variables.

The `summarise()` function is used across all numeric variables excepting `PWGTP` with the provided
weighted mean and standard deviation formulas. The resulting summary statistic is named according to
the column being summarized. The categorical variables are counted using `group_by()` on each
categorical variable, before creating a new variable called `Freq` using `summarize` to count
each level of those groups while scaling each row by `PWGTP`. The numeric summary tibbles are bound
together with a row for each summary statistic, in this case two, and a column for each numeric
variable summarized. This numeric summary tibble and the frequency tibble are finally returned as a
vector.

```{r Summary Function R2.2}
summary.census <- function(tibble, num_vars = NULL, cat_vars = NULL) {
    # Tibbles to store output
    mean_tibble <- sd_tibble <- freq_tibble <- NULL
    # Check if numeric variables are specified
    if (!is.null(num_vars)) {
        mean_tibble <- tibble |> summarise(across(all_of(num_vars) & !all_of(""),
                                         ~ sum(.x * PWGTP) / sum(PWGTP), .names = "{.col}_mean"))
        
        sd_tibble <- tibble |> summarise(across(all_of(num_vars) & !all_of("PWGTP"),
                        ~ sqrt(sum(.x^2 * PWGTP) / sum(PWGTP) - (sum(.x * PWGTP) / sum(PWGTP))^2 ),
                        .names = "{.col}_sd"))
    }
    # Check if categorical variables are specified
    if(!is.null(cat_vars)) {
        freq_tibble <- tibble |> group_by(across(all_of(cat_vars))) |>
                                    summarize(Freq = sum(PWGTP * n()))       
    }
    # Default - return summaries of all numeric and counts of all categorical
    if (is.null(num_vars) && is.null(cat_vars)) {

        mean_tibble <- tibble |> summarise(across(where(is.numeric) & !all_of("PWGTP"),
                                             ~ sum(.x * PWGTP) / sum(PWGTP), .names = "{.col}"))
            
        sd_tibble <- tibble |> summarise(across(where(is.numeric) & !all_of("PWGTP"),
                            ~ sqrt( sum(.x^2 * PWGTP) / sum(PWGTP) - (sum(.x * PWGTP) / sum(PWGTP))^2 ),
                            .names = "{.col}")) 
        
        freq_tibble <- tibble |> select(where(is.factor)) |> 
                                group_by(across(everything())) |>
                                summarize(Freq = sum(PWGTP * n()))
    }
    
    return(c(
        bind_rows(mean_tibble, sd_tibble) |>
            mutate(stat = c("Mean", "Standard Deviation")) |>
            select(stat, everything()), freq_tibble),
        freq_tibble
        )
}
```

R2.1 Create your own custom object class called census.

R2.2.4 Test out this function by running summary(*your_census_tibble*) on something you’ve returned from your census API function.

R2.3 - Similarly, let’s create a generic plot() function for a census class tibble. Require the user to specify one categorical variable and one numeric variable for plotting purposes.

```{r Plotting Function}
plot.census <- function() {
    ggplot(my_tibble,
           aes(x = get(cat_vars), y = get(num_vars), weight = PWGTP)) + 
            geom_boxplot()
}
```


```{r Summary Function Verification}
syear_test <- get_single_year(num_vars = c("PWGTP","AGEP"),
                       cat_vars = c("SEX", "JWTRNS"),
                       geography = "State", geography_level = c("02"))

class(syear_test) <- c("census", class(syear_test))

myear_test <- get_multi_years(years = c(2019, 2022), num_vars = c("PWGTP","AGEP"),
                       cat_vars = c("SEX", "JWTRNS"),
                       geography = "State", geography_level = c("02"))
    
class(myear_test) <- c("census", class(myear_test))

summary(syear_test)
summary(myear_test)

plot(syear_test)
plot(myear_test)
```
**Web Page**

R 3.1 - Your web page should have a narrative going through your process of creating the above functions and testing them.

R3.2 - You should have a section at the end where you investigate something interesting from the data using your API function and plotting/summarizing functions.
